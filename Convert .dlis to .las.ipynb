{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Source convert .dlis to .las v2.0 using dlisio and lasio python packages\n",
    "\n",
    "## Using DLISIO v0.1.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Still a work in progress.  Need to dos:\n",
    " - add functionality to manipulate the units of the index track because often it is in 0.1 in.\n",
    " - package into a function: done, on same github\n",
    " \n",
    "Work released under MIT License (MIT)\n",
    "\n",
    "## But this code will handle multiple embedded files within a dlis and multiple frames in a single dlis.  This code will also handle scenarios where values are actually lists of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lasio\n",
    "import dlisio\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = -999.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in the file path for the dlis you want to read in the below cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"...\\Volve_Well_logs_pr_WELL\\15_9-F-4\\02.LWD_EWL\\WL_RAW_BHPR-GR-MECH_MWD_1.DLIS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in the file path for where you want the output las file to go in the below cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_location = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.basename(filepath)\n",
    "filename = os.path.splitext(filename)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_files = []\n",
    "origins = []\n",
    "object_columns = []\n",
    "frame_count = 0\n",
    "object_warning = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_column_uniquify(df):\n",
    "    df_columns = df.columns\n",
    "    new_columns = []\n",
    "    for item in df_columns:\n",
    "        counter = 0\n",
    "        newitem = item\n",
    "        while newitem in new_columns:\n",
    "            counter += 1\n",
    "            newitem = \"{}_{}\".format(item, counter)\n",
    "        new_columns.append(newitem)\n",
    "    df.columns = new_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second we will read the dlis file for the curves values (from 2D arrays to pandas), expand out any values that are actually arrays, assign the index track, get the metadata, and output the .las files.  One file will be outputted per embedded file per frame.\n",
    "\n",
    "## From each frame, we will also get the channel metadata, including the long description and the units if they are filled out.  These will be written to the Curves section of the resultant .las files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dlisio.load(filepath) as file:\n",
    "    print(file.describe())\n",
    "    for d in file:\n",
    "        embedded_files.append(d)\n",
    "        frame_count = 0\n",
    "        for origin in d.origin:\n",
    "            origins.append(origin)\n",
    "        for fram in d.frames:\n",
    "            curves_L = []\n",
    "            curves_name = []\n",
    "            longs = []\n",
    "            unit = []\n",
    "            frame_count = frame_count + 1\n",
    "            for channel in fram.channels:\n",
    "                curves_name.append(channel.name)\n",
    "                longs.append(channel.long_name)\n",
    "                unit.append(channel.units)\n",
    "                curves = channel.curves()\n",
    "                curves_L.append(curves)\n",
    "            name_index = 0\n",
    "            las = lasio.LASFile()\n",
    "            curve_df = pd.DataFrame()\n",
    "            las_names = []\n",
    "            las_units = []\n",
    "            las_longs = []\n",
    "            for c in curves_L:\n",
    "                name = curves_name[name_index]\n",
    "                print(\"Processing \" + name)\n",
    "                units = unit[name_index]\n",
    "                long = longs[name_index]\n",
    "                c = np.vstack(c)\n",
    "                try:\n",
    "                    num_col = c.shape[1]\n",
    "                    col_name = [name] * num_col\n",
    "                    df = pd.DataFrame(data=c, columns=col_name)\n",
    "                    #df = df_column_uniquify(df)\n",
    "                    curve_df = pd.concat([curve_df, df], axis=1)\n",
    "                    name_index = name_index + 1\n",
    "                    object_warning = str(name) + ' had to be expanded in the final .las file, as it has multiple samples per index'\n",
    "                except:\n",
    "                    num_col = 1\n",
    "                    df = pd.DataFrame(data=c, columns=[name])\n",
    "                    name_index = name_index + 1\n",
    "                    curve_df = pd.concat([curve_df, df], axis=1)\n",
    "                    continue\n",
    "                u = [units] * num_col\n",
    "                l = [long] * num_col\n",
    "                las_units.append(u)\n",
    "                las_longs.append(l)\n",
    "                print(\"Completed \" + name)\n",
    "\n",
    "            las_units = [item for sublist in las_units for item in sublist]\n",
    "            las_longs = [item for sublist in las_longs for item in sublist]\n",
    "\n",
    "            #Check that the lists are ready for the curve metadata\n",
    "            print(\"If these are different lengths, something is wrong:\")\n",
    "            print(len(las_units))\n",
    "            print(len(las_longs))\n",
    "            curve_df = df_column_uniquify(curve_df)\n",
    "            curves_name = list(curve_df.columns.values)\n",
    "            print(len(curves_name))\n",
    "\n",
    "            #we will take the first curve in the frame as the index.\n",
    "            curve_df = curve_df.set_index(curves_name[0])\n",
    "            #write the pandas data to the las file\n",
    "            print(\"Writing to las... \")\n",
    "            las.set_data(curve_df)\n",
    "            #write the curve metadata from our three lists.\n",
    "            counter = 0\n",
    "            print(\"Writing las header...\")\n",
    "            for x in curves_name:\n",
    "                las.curves[x].unit = las_units[counter]\n",
    "                las.curves[x].descr = las_longs[counter]\n",
    "                counter=counter + 1\n",
    "            las.well.COMP = origin.company\n",
    "            las.well.WELL = origin.well_name\n",
    "            las.well.FLD = origin.field_name\n",
    "            las.well.SRVC = origin.producer_name\n",
    "            las.well.DATE = origin.creation_time\n",
    "            las.well.UWI = origin.well_id\n",
    "            las.well.API = origin.well_id\n",
    "            las.well.NULL = null\n",
    "            las.params['PROD'] = lasio.HeaderItem('PROD', value=origin.product)\n",
    "            las.params['PROG'] = lasio.HeaderItem('PROG', value=origin.programs)\n",
    "            las.params['RUN'] = lasio.HeaderItem('RUN', value=origin.run_nr)\n",
    "            las.params['DESCENT'] = lasio.HeaderItem('DESCENT', value=origin.descent_nr)\n",
    "            las.params['VERSION'] = lasio.HeaderItem('VERSION', value=origin.version)\n",
    "            las.params['LINEAGE'] = lasio.HeaderItem('LINEAGE', value=\"Python-converted from DLIS\")\n",
    "            las.params['ORFILE'] = lasio.HeaderItem('ORFILE', value=filepath)\n",
    "            las.write(output_file_location + \"\\\\\" + filename + \"_\" + 'converted_with_python_' + str(frame_count) + '.las', version=2)\n",
    "            print(\"number of logical files: \" + str(frame_count) + \": this is the number of .las files created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warnings :  You will get more than one las file as output if there are multiple files in a single .dlis or multiple frames in a single .dlis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This file has \" + str(len(origins)) + \" metadata headers.  This code has used the first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
